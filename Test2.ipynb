{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import pandas as pd\n",
    "import time\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_concatenated = './data/SFR/csv_concatenated.csv'\n",
    "data_file= './data/SFR/messages_formatted_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_concatenated, sep=';',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bonnes_categories(df):\n",
    "    #Prend un csv en entrée et rend un csv en sortie avec les bonnes catégories, et\n",
    "    #ne garde que les DIMELO et conv avec body et catégorie\n",
    "    print('Debut bonne categorie')\n",
    "    try:\n",
    "        cond = df.apply(lambda row: (row['source_type']=='Dimelo Chat') and (pd.isnull(row['body'])==False)\n",
    "                          and (pd.isnull(row['categories'])==False) , axis=1)\n",
    "    except:\n",
    "        cond = df.apply(lambda row: (pd.isnull(row['body'])==False)\n",
    "                              and (pd.isnull(row['categories'])==False) , axis=1)\n",
    "\n",
    "    df = df[cond]\n",
    "\n",
    "    for index, value in df.categories.iteritems():\n",
    "        df.set_value(index, 'categories',df.ix[index,'categories'].split(',')[0] )\n",
    "        if index%1000 ==0:\n",
    "            print (index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = bonnes_categories(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'created_at' in df.columns.values[0]:\n",
    "    df.columns.values[0]='created_at'\n",
    "    print ('created_at est bien dedans')\n",
    "    print('c quoi ce dawa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"pourquoi ça vient pas là\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fieldnames = ['created_at','categories','intervention_id','creator_name','body']\n",
    "#df_light = pd.DataFrame(index = range(0,len(self.df)),columns = fieldnames)\n",
    "i=0\n",
    "print('ça vient là')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    print('ok le premier')\n",
    "    if column not in fieldnames:\n",
    "        print(column)\n",
    "        del df[column]\n",
    "print('fin de la suppression des colonnes inutiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'intervention_id':['01','02','01','01','02'],'cat':['p','p','p','p','p'],\n",
    "     'body':['salualalallalalalalalallala',\"j'ai des problèmes avec red en ce moment\",\"j'ai un prob\",'quel est-il?',\"j'ai payé une facture de 14.51€ surplus imposé par red le 28/06/2016\"],\n",
    "     'date':['1','1','3','4','5'],'creator_name':['A','','','','']}\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace({'p': '5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fieldname2 = [u'creator_name',u'date',u'cat']\n",
    "for column in df:\n",
    "    print(column)\n",
    "    if column not in fieldname2:\n",
    "        del df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfmois = pd.read_csv('./data/SFR/rawdata/2016-06-red-messages.csv', sep=';',error_bad_lines=False)\n",
    "dfjour = pd.read_csv(\"./data/SFR/stockage_tempo/messages(29).csv\", sep=';',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfmois.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfjour.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_concatenated = './data/SFR/csv_concatenated_test.csv'\n",
    "\n",
    "def remove_bom(filename):\n",
    "    fp = open(filename, 'rbU')\n",
    "    fp.read(1)\n",
    "    return fp\n",
    "\n",
    "# read_table also accepts a file pointer, so we can remove the bom first\n",
    "samples = pd.read_table(remove_bom(csv_concatenated))\n",
    "\n",
    "print(samples['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_concatenated = './data/SFR/stockage_tempo/2016-04-red-messages.csv'\n",
    "df = pd.read_csv(csv_concatenated, sep=';',error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.values[1] = 'created_at'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(csv_concatenated,sep=';',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_concatenated, sep=';',error_bad_lines=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.values[0]='ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"\\ufeffok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conca = pd.read_csv('./data/SFR/messages_catégories_motifs.csv', delimiter=';',error_bad_lines=False)\n",
    "print (conca.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/SFR/messages_catégories_motifs.csv', delimiter=';',error_bad_lines=False)\n",
    "\n",
    "cond = df.apply(lambda row: (pd.isnull(row['intervention_id'])==False), axis=1)\n",
    "\n",
    "df = df[cond]\n",
    "\n",
    "del df['source_id']\n",
    "\n",
    "df.to_csv('./data/SFR/messages_preprocessing_final.csv',sep=';',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2 + and + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico = {'col1':[1,2,3,4]}\n",
    "df = pd.Series(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test_preprocessing.txt', 'rb') as sentences_npy:\n",
    "    sentences = np.array(np.load(sentences_npy,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic = [10**x for x in range(-4,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = {'1':{'1':{},'2':{},'3':{},'4':{}},'2':{},'3':{},'4':{},'F':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tree_function(liste,dico={}):\n",
    "    if len(liste)>1:\n",
    "        dico={}\n",
    "        dico[liste[0]]=tree_function(liste[1:],dico)\n",
    "        #print(1,dico)\n",
    "        return dico\n",
    "    else:\n",
    "        dico={}\n",
    "        dico[liste[0]]={}\n",
    "        #print(2,dico)\n",
    "        return dico\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ajout(liste,dico):\n",
    "    try:\n",
    "        if liste[0] in dico.keys():\n",
    "            dico[liste[0]] = ajout(liste[1:],dico[liste[0]])\n",
    "            return dico\n",
    "        else:\n",
    "            dico2 = tree_function(liste,dico={})\n",
    "            dico.update(dico2)\n",
    "            return dico\n",
    "    except:\n",
    "        print('Erreur, la branche existe déjà')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_branches(liste,dico):\n",
    "    for element in liste:\n",
    "        dico = ajout(element,dico)\n",
    "    return dico\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liste_position(tree,position,liste):\n",
    "    for element in tree.keys():\n",
    "        if tree[element]!={}:\n",
    "            position2 = copy(position)\n",
    "            position.append(element)\n",
    "            liste_position(tree[element],position,liste)\n",
    "            position = copy(position2)\n",
    "        else:\n",
    "            position2 = copy(position)\n",
    "            position.append(element)\n",
    "            liste.append(position)\n",
    "            position = copy(position2)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def liste_position_main(main_tree,parents,position_global,boolean):\n",
    "    \n",
    "    if boolean == True:\n",
    "        to = merge_parents_childs([],liste_position(main_tree,[],[]))\n",
    "        position_global.append(merge_parents_childs([],liste_position(main_tree,[],[])))\n",
    "        #position_global[()]=to\n",
    "        boolean = False\n",
    "    \n",
    "    for element in main_tree.keys():\n",
    "        if main_tree[element]!={}:\n",
    "            parents2 = copy(parents)\n",
    "            parents.append(element)\n",
    "            position_global.append(merge_parents_childs(parents,liste_position(main_tree[element],[],[])))\n",
    "            #position_global[tuple(parents)]= merge_parents_childs(parents,liste_position(main_tree[element],[],[]))\n",
    "            liste_position_main(main_tree[element],parents,position_global,boolean)\n",
    "            parents=copy(parents2)\n",
    "        else:\n",
    "            pass\n",
    "            #position_global.append(merge_parents_childs(parents,[[element]]))\n",
    "            #position_global[tuple(parents)]= merge_parents_childs(parents,[[element]])\n",
    "    return position_global\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_parents_childs(parents,childs):\n",
    "    merge =[]\n",
    "    for branch in childs:\n",
    "        merge.append(parents+branch)\n",
    "    for index,element in enumerate(merge):\n",
    "        string = '-'.join(element)\n",
    "        merge[index]=string\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_wrong_branch(tree):\n",
    "    try:\n",
    "        for element in tree.keys():\n",
    "            if tree[element]!={}:\n",
    "                dico=tree[element]\n",
    "                count = len(dico.keys())\n",
    "                if count == 1:\n",
    "                    del tree[element]\n",
    "                    for ele in dico.keys():\n",
    "                        new_element = element+'-'+ele\n",
    "                        tree[new_element]=dico[ele]\n",
    "                    merge_wrong_branch(tree)\n",
    "                else:\n",
    "                    merge_wrong_branch(tree[element])\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    return tree\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deno_commun(liste):\n",
    "    if len(liste)==1:\n",
    "        return liste[0]\n",
    "    else:\n",
    "        for ele in liste[1:]:\n",
    "            if ele[0] != liste[0][0]:\n",
    "                return''\n",
    "        for ele in liste[1:]:\n",
    "            if ele[2] != liste[0][2]:\n",
    "                return liste[0][0]\n",
    "        for ele in liste[1:]:\n",
    "            if ele[4] != liste[0][4]:\n",
    "                return liste[0][0]+'-'+liste[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ess = deno_commun(['F-1-4'])\n",
    "type(ess)\n",
    "ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dico_node(liste_node):\n",
    "    dico={}\n",
    "    for ind,ele in enumerate(liste_node):\n",
    "        key = deno_commun(ele)\n",
    "        dico[key]=ele\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "az = dico_node(test)\n",
    "az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = {'1': {'1': {}, '3': {'4': {}}, '2': {}, '4': {}, '7': {}}, '3': {'1': {}}, '2': {'3': {'2': {}}, '2': {'1': {}, '2': {}, '5': {}}}, '4': {'2': {}, '4': {'2': {}, '4': {}}}, 'F': {'1': {'4': {}}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree=merge_wrong_branch(tree)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = liste_position_main(tree,[],[],True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essai = merge_parents_childs([],liste_position(tree,[],[]))\n",
    "essai\n",
    "dico={}\n",
    "dico[()]=merge_parents_childs([],liste_position(tree,[],[]))\n",
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merging = merge_parents_childs(['1', '3'],[['3', '6'], ['3', '7'], ['2', '5'], ['2', '4']])\n",
    "merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = concatenate_branches([['a','b','c'],['a','b','b'],['a','c','a']],{})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico =ajout(['a','b','c'],{})\n",
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico = ajout(['a','b','c'],dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "data_directory = './data/tree_classifier/messages_motifs.csv'\n",
    "df = pd.read_csv(data_directory, sep=';')\n",
    "path_sentences = './data/inputs/tfidf/sentences.npy'\n",
    "path_labels = './data/inputs/tfidf/labels.npy'\n",
    "path_labels_1 = './data/inputs/tfidf/labels_1.npy'\n",
    "path_labels_2 = './data/inputs/tfidf/labels_2.npy'\n",
    "path_labels_3 = './data/inputs/tfidf/labels_3.npy'\n",
    "label_list=['label_1','label_2','label_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path_sentences, 'rb') as sentences_npy:\n",
    "    with open(path_labels_1, 'rb') as labels_1_npy:\n",
    "        with open(path_labels_2, 'rb') as labels_2_npy:\n",
    "            with open(path_labels_3, 'rb') as labels_3_npy:\n",
    "                    sentences = np.array(np.load(sentences_npy))\n",
    "                    labels_1 = np.array(np.load(labels_1_npy))\n",
    "                    labels_2 = np.array(np.load(labels_2_npy))\n",
    "                    labels_3 = np.array(np.load(labels_3_npy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_1,labels_2,labels_3),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(sentences, labels, test_size=0.20)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_val), 'validation sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=35760\n",
    "print(labels[i,0],labels[i,1],labels[i,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = df['label']\n",
    "label = label.replace({'F-1-4':'5-1-4'},regex=True)\n",
    "label = list(label.unique())\n",
    "print(label)\n",
    "label = [labe.split('-') for labe in label]\n",
    "tree = concatenate_branches(label,{})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree=merge_wrong_branch(tree)\n",
    "node = liste_position_main(tree,[],[],True)\n",
    "diconode = dico_node(node)\n",
    "print(diconode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def somme_str(raw):\n",
    "    if np.isnan(raw[2]):\n",
    "        return int(str(int(raw[0]))+str(int(raw[1])))\n",
    "    else:\n",
    "        return int(str(int(raw[0]))+str(int(raw[1]))+str(int(raw[2])))\n",
    "\n",
    "def concat_labs(labels):\n",
    "    new_labels=np.zeros((labels.shape[0], labels.shape[1]+1))\n",
    "    new_labels[:,0:new_labels.shape[1]-1]=labels\n",
    "    col = np.apply_along_axis( somme_str, axis=1, arr=labels )\n",
    "    new_labels[:,new_labels.shape[1]-1]=col\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_node=''\n",
    "key_node = key_node.split('-')\n",
    "num_label = len(key_node)\n",
    "y_train_select=y_train_select[:,num_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear\n",
    "model = linear.LogisticRegression(penalty='l2', C=3)\n",
    "model.fit(X_train_select,y_train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    ml_models = {}\n",
    "    ml_models['reglog_l2'] = [5]\n",
    "    from classifiers import deep_learning, machine_learning\n",
    "    \n",
    "    def train_node(node):\n",
    "\n",
    "        print('Debut entrainement du noeud',node)\n",
    "        label_selection = diconode[node]\n",
    "        print(label_selection)\n",
    "        for index,ele in enumerate(label_selection):\n",
    "            ele = ele.replace('-','')\n",
    "            label_selection[index]=int(ele)\n",
    "        see = concat_labs(y_train)\n",
    "        cond = np.in1d(see,label_selection)\n",
    "        print('Taille de la cond:',cond.shape)\n",
    "        y_train_select = y_train[cond]\n",
    "        X_train_select = X_train[cond]\n",
    "        print(\"Taille de la selection d'entrainement du noeud :\",X_train_select.shape)\n",
    "\n",
    "        node = node.split('-')\n",
    "        if node==['']:\n",
    "            num_label=0\n",
    "        else:\n",
    "            num_label = len(node)\n",
    "        print(num_label)\n",
    "        y_train_select=y_train_select[:,num_label]\n",
    "\n",
    "        ml = machine_learning.machine_learning()\n",
    "        for model_name, params_list in ml_models.items():\n",
    "            #results[model_name]={}\n",
    "            for params in params_list:\n",
    "                ml.build(model_name, params)\n",
    "                #results[model_name][params] = ml.predict()\n",
    "        print(\"Fin d'entrainement du noeud\",node)\n",
    "        return num_label,seeok,ml.train_tree(X_train_select,y_train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_tree_ml():\n",
    "\n",
    "    models = {}\n",
    "    for key,value in diconode.iteritems():\n",
    "        models[key] = train_node(key)\n",
    "\n",
    "def predict_tree_ml():\n",
    "\n",
    "    dico_prediction = {}\n",
    "    for key,value in models.iteritems():\n",
    "        dico_prediction[key] = value[2].predict(X_val)\n",
    "        \n",
    "def predict_node(pred_actuel,i):\n",
    "    if pred_actuel in diconode.keys():\n",
    "        pred_suiv = str(int(dico_prediction[pred_actuel][i]))\n",
    "        pred_actuel = pred_actuel+'-'+pred_suiv\n",
    "        if pred_actuel[0]=='-':\n",
    "            pred_actuel = pred_actuel[1:]\n",
    "        return predict_node(pred_actuel,i)\n",
    "    else:\n",
    "        return pred_actuel.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree=merge_wrong_branch(tree)\n",
    "node = liste_position_main(tree,[],[],True)\n",
    "diconode = dico_node(node)\n",
    "\n",
    "models = {}\n",
    "for key,value in diconode.iteritems():\n",
    "    models[key] = train_node(key)\n",
    "    \n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    dico_prediction = {}\n",
    "    for key,value in models.iteritems():\n",
    "        dico_prediction[key] = value[2].predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_prediction[''][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = np.zeros((y_val.shape[0],3))\n",
    "for i in range(0,y_val.shape[0]):\n",
    "    liste = predict_node('',i)\n",
    "    print(liste)\n",
    "    for index,ele in enumerate(liste):\n",
    "        prediction[i,index]=ele\n",
    "    for j in range(len(liste),3):\n",
    "        prediction[i,j]=np.nan\n",
    "    print(prediction[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "conformite = []\n",
    "for i in range(0,prediction.shape[0]):\n",
    "    conformite.append((y_val[i,0]==prediction[i,0] and y_val[i,1]==prediction[i,1] and y_val[i,2]==prediction[i,2]))\n",
    "\n",
    "result = sum(conformite)/prediction.shape[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conformite=(prediction==y_val)\n",
    "conformite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " print('Debut entrainement du noeud',node)\n",
    "    label_selection = diconode[node]\n",
    "    print(label_selection)\n",
    "    for index,ele in enumerate(label_selection):\n",
    "        print (ele)\n",
    "        ele = ele.replace('-','')\n",
    "        label_selection[index]=int(ele)\n",
    "    see = concat_labs(y_train)\n",
    "    cond = np.in1d(see,label_selection)\n",
    "    print('Taille de la cond:',cond.shape)\n",
    "    y_train_select = y_train[cond]\n",
    "    X_train_select = X_train[cond]\n",
    "    print(\"Taille de la selection d'entrainement du noeud :\",X_train.shape)\n",
    "\n",
    "    node = node.split('-')\n",
    "    if node=='':\n",
    "        num_label=1\n",
    "    else:\n",
    "        num_label = len(key_node)\n",
    "    y_train_select=y_train_select[:,num_label]\n",
    "\n",
    "    ml = machine_learning.machine_learning()\n",
    "    for model_name, params_list in ml_models.items():\n",
    "        #results[model_name]={}\n",
    "        for params in params_list:\n",
    "            ml.build(model_name, params)\n",
    "            #results[model_name][params] = ml.predict()\n",
    "    print(\"Fin d'entrainement du noeud\",node)\n",
    "    return num_label,cond,ml.train_tree(X_train_select,y_train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree=merge_wrong_branch(tree)\n",
    "node = liste_position_main(tree,[],[],True)\n",
    "diconode = dico_node(node)\n",
    "node='4'\n",
    "label_selection = diconode[node]\n",
    "\n",
    "for index,ele in enumerate(label_selection):\n",
    "    ele = ele.replace('-','')\n",
    "    label_selection[index]=int(ele)\n",
    "label_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "see = concat_labs(y_train)\n",
    "cond = np.in1d(see,label_selection)\n",
    "#print(cond)\n",
    "print('Taille de la cond:',cond.shape)\n",
    "y_train_select = y_train[cond]\n",
    "X_train_select = X_train[cond]\n",
    "print(\"Taille de la selection d'entrainement du noeud :\",X_train_select.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Taille de la selection d'entrainement du noeud :\",X_train_select.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_select = y_train[cond]\n",
    "y_train_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    node = node.split('-')\n",
    "    print(node)\n",
    "    if node=='':\n",
    "        num_label=1\n",
    "    else:\n",
    "        num_label = len(key_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_select=y_train_select[:,num_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml = machine_learning.machine_learning()\n",
    "ml.build('reglog_l2', 5)\n",
    "num_label,ml.train_tree(X_train_select,y_train_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "from __future__ import division\n",
    "import pickle, operator, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from formatting.csv_threads import csv_threads\n",
    "from preprocessing.parse import preprocessing\n",
    "from classifiers import deep_learning, machine_learning\n",
    "from embeddings import tfidf, word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ner.train import ner\n",
    "from classifiers import train\n",
    "from copy import copy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_directory = './data/SFR/messages_formated_cat.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_wrong_branch(tree):\n",
    "    try: #probleme du bug impossible à régler\n",
    "        for element in tree.keys():\n",
    "            if tree[element]!={}:\n",
    "                dico=tree[element]\n",
    "                count = len(dico.keys())\n",
    "                if count == 1:\n",
    "                    del tree[element]\n",
    "                    for ele in dico.keys():\n",
    "                        new_element = element+'-'+ele\n",
    "                        tree[new_element]=dico[ele]\n",
    "                    merge_wrong_branch(tree)\n",
    "                else:\n",
    "                    merge_wrong_branch(tree[element])\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "def tree_function(liste,dico={}):\n",
    "    if len(liste)>1:\n",
    "        dico={}\n",
    "        dico[liste[0]]=tree_function(liste[1:],dico)\n",
    "        #print(1,dico)\n",
    "        return dico\n",
    "    else:\n",
    "        dico={}\n",
    "        dico[liste[0]]={}\n",
    "        #print(2,dico)\n",
    "        return dico\n",
    "\n",
    "def ajout(liste,dico):\n",
    "    try:\n",
    "        if liste[0] in dico.keys():\n",
    "            dico[liste[0]] = ajout(liste[1:],dico[liste[0]])\n",
    "            return dico\n",
    "        else:\n",
    "            dico2 = tree_function(liste,dico={})\n",
    "            dico.update(dico2)\n",
    "            return dico\n",
    "    except:\n",
    "        print('Erreur, la branche existe déjà')\n",
    "\n",
    "def concatenate_branches(liste,dico):\n",
    "    for element in liste:\n",
    "        dico = ajout(element,dico)\n",
    "    return dico\n",
    "\n",
    "def merge_parents_childs(parents,childs):\n",
    "    merge =[]\n",
    "    for branch in childs:\n",
    "        merge.append(parents+branch)\n",
    "    for index,element in enumerate(merge):\n",
    "        string = '-'.join(element)\n",
    "        merge[index]=string\n",
    "    return merge\n",
    "\n",
    "def liste_position(tree,position,liste):\n",
    "    for element in tree.keys():\n",
    "        if tree[element]!={}:\n",
    "            position2 = copy(position)\n",
    "            position.append(element)\n",
    "            liste_position(tree[element],position,liste)\n",
    "            position = copy(position2)\n",
    "        else:\n",
    "            position2 = copy(position)\n",
    "            position.append(element)\n",
    "            liste.append(position)\n",
    "            position = copy(position2)\n",
    "    return liste\n",
    "\n",
    "def liste_position_main(main_tree,parents,position_global,boolean):\n",
    "\n",
    "    if boolean == True:\n",
    "        position_global.append(merge_parents_childs([],liste_position(main_tree,[],[])))\n",
    "        boolean = False\n",
    "\n",
    "    for element in main_tree.keys():\n",
    "        if main_tree[element]!={}:\n",
    "            parents2 = copy(parents)\n",
    "            parents.append(element)\n",
    "            position_global.append(merge_parents_childs(parents,liste_position(main_tree[element],[],[])))\n",
    "            liste_position_main(main_tree[element],parents,position_global,boolean)\n",
    "            parents=copy(parents2)\n",
    "        else:\n",
    "            #position_global.append(merge_parents_childs(parents,[[element]]))\n",
    "            pass\n",
    "    return position_global\n",
    "\n",
    "def deno_commun(liste):\n",
    "    if len(liste)==1:\n",
    "        return liste[0]\n",
    "    else:\n",
    "        for ele in liste[1:]:\n",
    "            if ele[0] != liste[0][0]:\n",
    "                return''\n",
    "        for ele in liste[1:]:\n",
    "            if ele[2] != liste[0][2]:\n",
    "                return liste[0][0]\n",
    "        for ele in liste[1:]:\n",
    "            if ele[4] != liste[0][4]:\n",
    "                return liste[0][0]+'-'+liste[0][2]\n",
    "\n",
    "def dico_node(liste_node):\n",
    "    dico={}\n",
    "    for ind,ele in enumerate(liste_node):\n",
    "        key = deno_commun(ele)\n",
    "        dico[key]=ele\n",
    "    return dico\n",
    "\n",
    "def somme_str(raw):\n",
    "    if np.isnan(raw[2]):\n",
    "        return int(str(int(raw[0]))+str(int(raw[1])))\n",
    "    else:\n",
    "        return int(str(int(raw[0]))+str(int(raw[1]))+str(int(raw[2])))\n",
    "\n",
    "def concat_labs(labels):\n",
    "    new_labels=np.zeros((labels.shape[0], labels.shape[1]+1))\n",
    "    new_labels[:,0:new_labels.shape[1]-1]=labels\n",
    "    col = np.apply_along_axis( somme_str, axis=1, arr=labels )\n",
    "    new_labels[:,new_labels.shape[1]-1]=col\n",
    "    return col\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class tree_classifier():\n",
    "\n",
    "    def __init__(self, data_directory, word_label=True):\n",
    "        #initialize\n",
    "        self.data_directory = data_directory\n",
    "        self.df = pd.read_csv(self.data_directory, sep=';')\n",
    "        self.path_sentences = './data/inputs/tfidf/sentences.npy'\n",
    "        self.path_labels = './data/inputs/tfidf/labels.npy'\n",
    "        self.path_labels_1 = './data/inputs/tfidf/labels_1.npy'\n",
    "        self.path_labels_2 = './data/inputs/tfidf/labels_2.npy'\n",
    "        self.path_labels_3 = './data/inputs/tfidf/labels_3.npy'\n",
    "        self.label_list=['label_1','label_2','label_3']\n",
    "\n",
    "    def vectorize_and_split(self,test_size = 0.20):\n",
    "        # compute tfidf and transform the sentences into tfidf vectors, with feature selection (best tfidf weights)\n",
    "        self.tfidf = tfidf.tfidf()\n",
    "        if not os.path.exists('./tmp/tfidf.pkl'):\n",
    "            self.tfidf.train('./data/inputs/sentences.txt')\n",
    "            self.tfidf.format_input_tree()\n",
    "\n",
    "        with open(self.path_sentences, 'rb') as sentences_npy:\n",
    "            with open(self.path_labels_1, 'rb') as labels_1_npy:\n",
    "                with open(self.path_labels_2, 'rb') as labels_2_npy:\n",
    "                    with open(self.path_labels_3, 'rb') as labels_3_npy:\n",
    "                            sentences = np.array(np.load(sentences_npy))\n",
    "                            sentences = sentences[0:200,:]\n",
    "                            labels_1 = np.array(np.load(labels_1_npy))\n",
    "                            labels_1 = labels_1[0:200,:]\n",
    "                            labels_2 = np.array(np.load(labels_2_npy))\n",
    "                            labels_2 = labels_2[0:200,:]\n",
    "                            labels_3 = np.array(np.load(labels_3_npy))\n",
    "                            labels_3 = labels_3[0:200,:]\n",
    "                            self.labels = np.concatenate((labels_1,labels_2,labels_3),axis=1)\n",
    "                            X_train, X_val, y_train, y_val = train_test_split(sentences, self.labels, test_size=test_size)\n",
    "\n",
    "                            self.X_train = X_train\n",
    "                            self.X_val = X_val\n",
    "                            self.y_train = y_train\n",
    "                            self.y_val = y_val\n",
    "\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        print(len(X_train), 'train sequences')\n",
    "        print(len(X_val), 'validation sequences')\n",
    "\n",
    "    def generate_tree(self):\n",
    "        # generate the tree representing the motifs\n",
    "        label = self.df['label']\n",
    "        label = label.replace({'F-1-4':'5-1-4'},regex=True)\n",
    "        label = list(label.unique())\n",
    "        label = [labe.split('-') for labe in label]\n",
    "        self.tree = concatenate_branches(label,{})\n",
    "        print(self.tree)\n",
    "\n",
    "    def generate_label_at_node(self):\n",
    "        self.tree=merge_wrong_branch(self.tree)\n",
    "        self.node = liste_position_main(self.tree,[],[],True)\n",
    "        self.diconode = dico_node(self.node)\n",
    "        print(self.diconode)\n",
    "        print(len(self.node))\n",
    "\n",
    "    def train_node(self,node):\n",
    "\n",
    "        print('Debut entrainement du noeud',node)\n",
    "        label_selection = self.diconode[node]\n",
    "        for index,ele in enumerate(label_selection):\n",
    "            ele = ele.replace('-','')\n",
    "            label_selection[index]=int(ele)\n",
    "        see = concat_labs(self.y_train)\n",
    "        cond = np.in1d(see,label_selection)\n",
    "        y_train_select = self.y_train[cond]\n",
    "        X_train_select = self.X_train[cond]\n",
    "        print(\"Taille de la selection d'entrainement du noeud :\",X_train_select.shape)\n",
    "\n",
    "        node = node.split('-')\n",
    "        if node ==['']:\n",
    "            num_label=0\n",
    "        else:\n",
    "            num_label = len(node)\n",
    "        y_train_select=y_train_select[:,num_label]\n",
    "\n",
    "        ml = machine_learning.machine_learning()\n",
    "        for model_name, params_list in ml_models.items():\n",
    "            #results[model_name]={}\n",
    "            for params in params_list:\n",
    "                ml.build(model_name, params)\n",
    "                result = ml.train_tree(X_train_select,y_train_select)\n",
    "                #results[model_name][params] = ml.predict()\n",
    "        print(\"Fin d'entrainement du noeud\",node)\n",
    "        return num_label,cond,result\n",
    "\n",
    "\n",
    "    def train_tree_ml(self):\n",
    "\n",
    "        self.models = {}\n",
    "        for key,value in self.diconode.iteritems():\n",
    "            self.models[key] = self.train_node(key)\n",
    "\n",
    "    def classifier_tree_ml(self):\n",
    "\n",
    "        self.dico_prediction = {}\n",
    "        for key,value in self.models.iteritems():\n",
    "            self.dico_prediction[key] = value[2].predict(self.X_val)\n",
    "\n",
    "    def predict_node(self,pred_actuel,i):\n",
    "        if pred_actuel in self.diconode.keys():\n",
    "            pred_suiv = str(int(self.dico_prediction[pred_actuel][i]))\n",
    "            pred_actuel = pred_actuel+'-'+pred_suiv\n",
    "            if pred_actuel[0]=='-':\n",
    "                pred_actuel = pred_actuel[1:]\n",
    "            return self.predict_node(pred_actuel,i)\n",
    "        else:\n",
    "            return pred_actuel.split('-')\n",
    "\n",
    "    def tree_prediction(self):\n",
    "        self.prediction = np.zeros((self.y_val.shape[0],3))\n",
    "        for i in range(0,self.y_val.shape[0]):\n",
    "            liste = self.predict_node('',i)\n",
    "            for index,ele in enumerate(liste):\n",
    "                self.prediction[i,index]=ele\n",
    "            for j in range(len(liste),3):\n",
    "                self.prediction[i,j]=np.nan\n",
    "\n",
    "    def accuracy_tree(self):\n",
    "        conformite = []\n",
    "        for i in range(0,self.prediction.shape[0]):\n",
    "            conformite.append((self.y_val[i,0]==self.prediction[i,0] and self.y_val[i,1]==self.prediction[i,1] and self.y_val[i,2]==self.prediction[i,2]))\n",
    "        print(\"Précision:\",sum(conformite)/self.prediction.shape[0])\n",
    "\n",
    "    def accuracy_node(self,node):\n",
    "        y_prediction = self.dico_prediction[node]\n",
    "        print(y_prediction.shape)\n",
    "        \n",
    "        label_selection = self.diconode[node]\n",
    "        print(label_selection)\n",
    "        #for index,ele in enumerate(label_selection):\n",
    "            #ele = ele.replace('-','')\n",
    "            #label_selection[index]=int(ele)\n",
    "        see = concat_labs(self.y_val)\n",
    "        cond = np.in1d(see,label_selection)\n",
    "        \n",
    "        print(self.y_val.shape)\n",
    "        print(cond.shape)\n",
    "        \n",
    "        y_val_select = self.y_val[cond]\n",
    "        \n",
    "        node = node.split('-')\n",
    "        if node ==['']:\n",
    "            num_label=0\n",
    "        else:\n",
    "            num_label = len(node)\n",
    "        y_val_select=y_val_select[:,num_label]\n",
    "        \n",
    "        y_prediction_select = y_prediction[cond]\n",
    "        conformite = (y_val_select==y_prediction_select)\n",
    "        accuracy_node = np.sum(conformite)/y_val_select.shape[0]\n",
    "        print(accuracy_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    deep = False\n",
    "    # dictionary that links machine learning models to their parameters\n",
    "    ml_models = {}\n",
    "    basic = [10**x for x in range(-3,3)]\n",
    "    #ml_models['reglog_l1'] = [10]  # C\n",
    "    ml_models['reglog_l2'] = [1]  # C\n",
    "    #ml_models['reglog_sgd'] = 0.0001  # alpha\n",
    "    #ml_models['naive_bayes'] = ''\n",
    "    #ml_models['decision_tree'] = 'gini'  # entropy\n",
    "    #ml_models['random_forest'] = [100]  # nb_estimator\n",
    "    #ml_models['bagging_reglog_l1'] = 5  # nb_estimator\n",
    "    #ml_models['bagging_reglog_l2'] = 5  # nb_estimator\n",
    "    #ml_models['svm_linear'] = 1.0  # C\n",
    "    #ml_models['knn'] = 5  # nb_neighbors\n",
    "\n",
    "    data_directory = './data/SFR/messages_formated_cat.csv'\n",
    "    data_directory_2 = './data/tree_classifier/messages_motifs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((160, 24532), (160, 3))\n",
      "(160, 'train sequences')\n",
      "(40, 'validation sequences')\n",
      "{'1': {'1': {}, '3': {'4': {}}, '2': {}, '4': {}, '7': {}}, '3': {'1': {}}, '2': {'3': {'2': {}}, '2': {'1': {}, '2': {}, '5': {}}}, '5': {'1': {'4': {}}}, '4': {'2': {}, '4': {'2': {}, '4': {}}}}\n",
      "{'': ['3-1', '1-3-4', '1-1', '1-2', '1-4', '1-7', '2-2-1', '2-2-2', '2-2-5', '2-3-2', '4-2', '4-4-2', '4-4-4', '5-1-4'], '2-2': ['2-2-1', '2-2-2', '2-2-5'], '4-4': ['4-4-2', '4-4-4'], '1': ['1-3-4', '1-1', '1-2', '1-4', '1-7'], '2': ['2-2-1', '2-2-2', '2-2-5', '2-3-2'], '4': ['4-2', '4-4-2', '4-4-4']}\n",
      "6\n",
      "('Debut entrainement du noeud', '')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (160, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", [''])\n",
      "('Debut entrainement du noeud', '2-2')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (28, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", ['2', '2'])\n",
      "('Debut entrainement du noeud', '4-4')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (29, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", ['4', '4'])\n",
      "('Debut entrainement du noeud', '1')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (73, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", ['1'])\n",
      "('Debut entrainement du noeud', '2')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (48, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", ['2'])\n",
      "('Debut entrainement du noeud', '4')\n",
      "(\"Taille de la selection d'entrainement du noeud :\", (32, 24532))\n",
      "...Build model...\n",
      "...Train...\n",
      "(\"Fin d'entrainement du noeud\", ['4'])\n",
      "('Pr\\xc3\\xa9cision:', 0.0)\n"
     ]
    }
   ],
   "source": [
    "    classifier = tree_classifier(data_directory_2)\n",
    "    classifier.vectorize_and_split()\n",
    "    classifier.generate_tree()\n",
    "    classifier.generate_label_at_node()\n",
    "    classifier.train_tree_ml()\n",
    "    classifier.classifier_tree_ml()\n",
    "    classifier.tree_prediction()\n",
    "    classifier.accuracy_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n",
      "[221, 222, 225]\n",
      "(40, 3)\n",
      "(40,)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "classifier.accuracy_node('2-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
